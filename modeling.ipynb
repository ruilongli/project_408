{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sec_api import QueryApi\n",
    "from sec_api import ExtractorApi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RAW_DATA_PATH = 'C:/Users/Lenovo/OneDrive - The Chinese University of Hong Kong/lrl_study/cuhk_dmdp/summer quarter/ds/project'  # raw data save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2042 entries, 23 to 137006\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   gvkey     2042 non-null   int64  \n",
      " 1   splticrm  2042 non-null   object \n",
      " 2   datadate  2042 non-null   object \n",
      " 3   cik       2042 non-null   float64\n",
      " 4   conm      2041 non-null   object \n",
      " 5   year      2042 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 111.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>splticrm</th>\n",
       "      <th>datadate</th>\n",
       "      <th>cik</th>\n",
       "      <th>conm</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1004</td>\n",
       "      <td>BB</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1010</td>\n",
       "      <td>B+</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>910627.0</td>\n",
       "      <td>ACF INDUSTRIES INC</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1045</td>\n",
       "      <td>B-</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>6201.0</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1048</td>\n",
       "      <td>A-</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>65695.0</td>\n",
       "      <td>ANR PIPELINE CO</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1075</td>\n",
       "      <td>BBB-</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>764622.0</td>\n",
       "      <td>PINNACLE WEST CAPITAL CORP</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gvkey splticrm    datadate       cik                         conm  year\n",
       "23    1004       BB  2010-12-31    1750.0                     AAR CORP  2010\n",
       "26    1010       B+  2010-03-31  910627.0           ACF INDUSTRIES INC  2010\n",
       "74    1045       B-  2010-12-31    6201.0  AMERICAN AIRLINES GROUP INC  2010\n",
       "77    1048       A-  2010-03-31   65695.0              ANR PIPELINE CO  2010\n",
       "125   1075     BBB-  2010-12-31  764622.0   PINNACLE WEST CAPITAL CORP  2010"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import s&p rating data\n",
    "df_SP_rating = pd.read_csv(join(RAW_DATA_PATH, 'rating_2010_2011_sp1.csv'))\n",
    "# eliminate forecasts with missing announcement dates, gvkey and ranking\n",
    "\n",
    "df_SP_rating = df_SP_rating.dropna(subset=['gvkey','splticrm','datadate','cik'], how='any')\n",
    "\n",
    "df_SP_rating[['year']]=pd.to_datetime(df_SP_rating['datadate']).dt.year\n",
    "df_SP_rating=df_SP_rating.drop_duplicates(['gvkey', 'year'], keep='last')#here we keep the last record that year as the credit rating\n",
    "df_SP_rating=df_SP_rating.drop(['cusip','tic','spsdrm'],axis=1)\n",
    "df_SP_rating.info()\n",
    "df_SP_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8036 entries, 11 to 51274\n",
      "Data columns (total 76 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   gvkey            8036 non-null   int64  \n",
      " 1   adate            8014 non-null   object \n",
      " 2   qdate            8036 non-null   object \n",
      " 3   public_date      8036 non-null   object \n",
      " 4   CAPEI            7873 non-null   float64\n",
      " 5   bm               7774 non-null   float64\n",
      " 6   evm              7993 non-null   float64\n",
      " 7   pe_op_basic      7709 non-null   float64\n",
      " 8   pe_op_dil        7713 non-null   float64\n",
      " 9   pe_exi           7730 non-null   float64\n",
      " 10  pe_inc           7730 non-null   float64\n",
      " 11  ps               7901 non-null   float64\n",
      " 12  pcf              8006 non-null   float64\n",
      " 13  dpr              5639 non-null   float64\n",
      " 14  npm              7900 non-null   float64\n",
      " 15  opmbd            7900 non-null   float64\n",
      " 16  opmad            7900 non-null   float64\n",
      " 17  gpm              7890 non-null   float64\n",
      " 18  ptpm             7900 non-null   float64\n",
      " 19  cfm              7880 non-null   float64\n",
      " 20  roa              8008 non-null   float64\n",
      " 21  roe              7726 non-null   float64\n",
      " 22  roce             7971 non-null   float64\n",
      " 23  efftax           4920 non-null   float64\n",
      " 24  aftret_eq        8008 non-null   float64\n",
      " 25  aftret_invcapx   7872 non-null   float64\n",
      " 26  aftret_equity    8008 non-null   float64\n",
      " 27  pretret_noa      6475 non-null   float64\n",
      " 28  pretret_earnat   6475 non-null   float64\n",
      " 29  GProf            8013 non-null   float64\n",
      " 30  equity_invcap    7957 non-null   float64\n",
      " 31  debt_invcap      7929 non-null   float64\n",
      " 32  totdebt_invcap   7917 non-null   float64\n",
      " 33  capital_ratio    7989 non-null   float64\n",
      " 34  int_debt         5272 non-null   float64\n",
      " 35  int_totdebt      5650 non-null   float64\n",
      " 36  cash_lt          8015 non-null   float64\n",
      " 37  invt_act         6428 non-null   float64\n",
      " 38  rect_act         6469 non-null   float64\n",
      " 39  debt_at          7977 non-null   float64\n",
      " 40  debt_ebitda      7955 non-null   float64\n",
      " 41  short_debt       6751 non-null   float64\n",
      " 42  curr_debt        6482 non-null   float64\n",
      " 43  lt_debt          7989 non-null   float64\n",
      " 44  profit_lct       6482 non-null   float64\n",
      " 45  ocf_lct          6479 non-null   float64\n",
      " 46  cash_debt        7947 non-null   float64\n",
      " 47  fcf_ocf          6766 non-null   float64\n",
      " 48  lt_ppent         7925 non-null   float64\n",
      " 49  dltt_be          7746 non-null   float64\n",
      " 50  debt_assets      8015 non-null   float64\n",
      " 51  debt_capital     7959 non-null   float64\n",
      " 52  de_ratio         8015 non-null   float64\n",
      " 53  intcov           5898 non-null   float64\n",
      " 54  intcov_ratio     5896 non-null   float64\n",
      " 55  cash_ratio       6484 non-null   float64\n",
      " 56  quick_ratio      6482 non-null   float64\n",
      " 57  curr_ratio       6484 non-null   float64\n",
      " 58  cash_conversion  6013 non-null   float64\n",
      " 59  inv_turn         6114 non-null   float64\n",
      " 60  at_turn          7898 non-null   float64\n",
      " 61  rect_turn        7808 non-null   float64\n",
      " 62  pay_turn         7812 non-null   float64\n",
      " 63  sale_invcap      7846 non-null   float64\n",
      " 64  sale_equity      7648 non-null   float64\n",
      " 65  sale_nwc         5715 non-null   float64\n",
      " 66  rd_sale          8017 non-null   float64\n",
      " 67  adv_sale         7881 non-null   float64\n",
      " 68  staff_sale       7881 non-null   float64\n",
      " 69  accrual          8008 non-null   float64\n",
      " 70  ptb              7774 non-null   float64\n",
      " 71  PEG_trailing     3290 non-null   float64\n",
      " 72  divyield         2630 non-null   object \n",
      " 73  PEG_1yrforward   5413 non-null   float64\n",
      " 74  PEG_ltgforward   4016 non-null   float64\n",
      " 75  year             8036 non-null   int64  \n",
      "dtypes: float64(70), int64(2), object(4)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#import financial ratio data\n",
    "# import s&p rating data\n",
    "df_financial_ratio = pd.read_csv(join(RAW_DATA_PATH, 'financial ratio.csv'))\n",
    "# eliminate forecasts with missing announcement dates, gvkey and ranking\n",
    "df_financial_ratio = df_financial_ratio.dropna(subset=['gvkey','public_date'], how='any')\n",
    "#creat a variable called year for later merging data\n",
    "df_financial_ratio[['year']]=pd.to_datetime(df_financial_ratio['public_date']).dt.year\n",
    "df_financial_ratio=df_financial_ratio.drop_duplicates(['gvkey', 'year'], keep='last') \n",
    "df_financial_ratio=df_financial_ratio.drop(['cusip','TICKER','permno'],axis=1)#drop some non-used variable\n",
    "df_financial_ratio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1106 entries, 0 to 1105\n",
      "Data columns (total 80 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   gvkey            1106 non-null   int64  \n",
      " 1   adate            1106 non-null   object \n",
      " 2   qdate            1106 non-null   object \n",
      " 3   public_date      1106 non-null   object \n",
      " 4   CAPEI            1102 non-null   float64\n",
      " 5   bm               1048 non-null   float64\n",
      " 6   evm              1101 non-null   float64\n",
      " 7   pe_op_basic      1073 non-null   float64\n",
      " 8   pe_op_dil        1073 non-null   float64\n",
      " 9   pe_exi           1071 non-null   float64\n",
      " 10  pe_inc           1072 non-null   float64\n",
      " 11  ps               1106 non-null   float64\n",
      " 12  pcf              1105 non-null   float64\n",
      " 13  dpr              934 non-null    float64\n",
      " 14  npm              1106 non-null   float64\n",
      " 15  opmbd            1106 non-null   float64\n",
      " 16  opmad            1106 non-null   float64\n",
      " 17  gpm              1106 non-null   float64\n",
      " 18  ptpm             1106 non-null   float64\n",
      " 19  cfm              1103 non-null   float64\n",
      " 20  roa              1105 non-null   float64\n",
      " 21  roe              1042 non-null   float64\n",
      " 22  roce             1103 non-null   float64\n",
      " 23  efftax           830 non-null    float64\n",
      " 24  aftret_eq        1105 non-null   float64\n",
      " 25  aftret_invcapx   1097 non-null   float64\n",
      " 26  aftret_equity    1105 non-null   float64\n",
      " 27  pretret_noa      941 non-null    float64\n",
      " 28  pretret_earnat   941 non-null    float64\n",
      " 29  GProf            1106 non-null   float64\n",
      " 30  equity_invcap    1104 non-null   float64\n",
      " 31  debt_invcap      1104 non-null   float64\n",
      " 32  totdebt_invcap   1102 non-null   float64\n",
      " 33  capital_ratio    1106 non-null   float64\n",
      " 34  int_debt         1033 non-null   float64\n",
      " 35  int_totdebt      1034 non-null   float64\n",
      " 36  cash_lt          1106 non-null   float64\n",
      " 37  invt_act         933 non-null    float64\n",
      " 38  rect_act         942 non-null    float64\n",
      " 39  debt_at          1104 non-null   float64\n",
      " 40  debt_ebitda      1099 non-null   float64\n",
      " 41  short_debt       1089 non-null   float64\n",
      " 42  curr_debt        943 non-null    float64\n",
      " 43  lt_debt          1106 non-null   float64\n",
      " 44  profit_lct       943 non-null    float64\n",
      " 45  ocf_lct          942 non-null    float64\n",
      " 46  cash_debt        1100 non-null   float64\n",
      " 47  fcf_ocf          1073 non-null   float64\n",
      " 48  lt_ppent         1086 non-null   float64\n",
      " 49  dltt_be          1049 non-null   float64\n",
      " 50  debt_assets      1106 non-null   float64\n",
      " 51  debt_capital     1085 non-null   float64\n",
      " 52  de_ratio         1106 non-null   float64\n",
      " 53  intcov           1041 non-null   float64\n",
      " 54  intcov_ratio     1041 non-null   float64\n",
      " 55  cash_ratio       943 non-null    float64\n",
      " 56  quick_ratio      943 non-null    float64\n",
      " 57  curr_ratio       943 non-null    float64\n",
      " 58  cash_conversion  900 non-null    float64\n",
      " 59  inv_turn         888 non-null    float64\n",
      " 60  at_turn          1105 non-null   float64\n",
      " 61  rect_turn        1094 non-null   float64\n",
      " 62  pay_turn         1061 non-null   float64\n",
      " 63  sale_invcap      1104 non-null   float64\n",
      " 64  sale_equity      1044 non-null   float64\n",
      " 65  sale_nwc         806 non-null    float64\n",
      " 66  rd_sale          1106 non-null   float64\n",
      " 67  adv_sale         1106 non-null   float64\n",
      " 68  staff_sale       1106 non-null   float64\n",
      " 69  accrual          1105 non-null   float64\n",
      " 70  ptb              1048 non-null   float64\n",
      " 71  PEG_trailing     520 non-null    float64\n",
      " 72  divyield         579 non-null    object \n",
      " 73  PEG_1yrforward   964 non-null    float64\n",
      " 74  PEG_ltgforward   845 non-null    float64\n",
      " 75  year             1106 non-null   int64  \n",
      " 76  splticrm         1106 non-null   object \n",
      " 77  datadate         1106 non-null   object \n",
      " 78  cik              1106 non-null   object \n",
      " 79  conm             1106 non-null   object \n",
      "dtypes: float64(70), int64(2), object(8)\n",
      "memory usage: 699.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#creat veariable for corresponding year and merge with respect to year and compnay gvkey\n",
    "#check duplicate\n",
    "df_merged=df_financial_ratio.merge(df_SP_rating, on =['gvkey','year'])\n",
    "df_merged['cik']=df_merged['cik'].astype(int).astype(str)\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'divyield'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'divyield'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a278b4d20d8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"divyield\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"divyield\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmissing_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_merged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;31m#drop variables with over 100 missing value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_merged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_merged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns_to_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#drop varaivles with any missing value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcredit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'divyield'"
     ]
    }
   ],
   "source": [
    "df_merged[\"divyield\"] = pd.to_numeric(df_merged[\"divyield\"].str.replace('%', ''), errors='coerce') / 100\n",
    "missing_values = df_merged.isnull().sum()\n",
    "columns_to_drop = missing_values[missing_values > 100].index#drop variables with over 100 missing value\n",
    "df_merged = df_merged.drop(columns=columns_to_drop).dropna().reset_index()#drop varaivles with any missing value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAPEI',\n",
       " 'bm',\n",
       " 'evm',\n",
       " 'pe_op_basic',\n",
       " 'pe_op_dil',\n",
       " 'pe_exi',\n",
       " 'pe_inc',\n",
       " 'ps',\n",
       " 'pcf',\n",
       " 'npm',\n",
       " 'opmbd',\n",
       " 'opmad',\n",
       " 'gpm',\n",
       " 'ptpm',\n",
       " 'cfm',\n",
       " 'roa',\n",
       " 'roe',\n",
       " 'roce',\n",
       " 'aftret_eq',\n",
       " 'aftret_invcapx',\n",
       " 'aftret_equity',\n",
       " 'GProf',\n",
       " 'equity_invcap',\n",
       " 'debt_invcap',\n",
       " 'totdebt_invcap',\n",
       " 'capital_ratio',\n",
       " 'int_debt',\n",
       " 'int_totdebt',\n",
       " 'cash_lt',\n",
       " 'debt_at',\n",
       " 'debt_ebitda',\n",
       " 'short_debt',\n",
       " 'lt_debt',\n",
       " 'cash_debt',\n",
       " 'fcf_ocf',\n",
       " 'lt_ppent',\n",
       " 'dltt_be',\n",
       " 'debt_assets',\n",
       " 'debt_capital',\n",
       " 'de_ratio',\n",
       " 'intcov',\n",
       " 'intcov_ratio',\n",
       " 'at_turn',\n",
       " 'rect_turn',\n",
       " 'pay_turn',\n",
       " 'sale_invcap',\n",
       " 'sale_equity',\n",
       " 'rd_sale',\n",
       " 'adv_sale',\n",
       " 'staff_sale',\n",
       " 'accrual',\n",
       " 'ptb']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all names of the financial ratios into a list\n",
    "credit = df_merged\n",
    "ratio_name = credit.select_dtypes(include='float').columns.tolist()\n",
    "ratio_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to implement the examination of outliers\n",
    "def winsorize_data(data):\n",
    "    # Calculate the 1% and 99% percentiles\n",
    "    p1 = np.percentile(data, 1)\n",
    "    p99 = np.percentile(data, 99)\n",
    "\n",
    "    # Winsorize the data\n",
    "    winsorized_data = np.where(data < p1, p1, data)\n",
    "    winsorized_data = np.where(data > p99, p99, winsorized_data)\n",
    "\n",
    "    return winsorized_data\n",
    "\n",
    "\n",
    "\n",
    "for column in ratio_name:\n",
    "    column_data = credit[column]\n",
    "    winsorized_data = winsorize_data(column_data)\n",
    "    credit[column] = winsorized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode the dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_junk_bond(rating):\n",
    "    # Assign numerical values to credit ratings\n",
    "    rating_values = {\n",
    "        'D': 0,\n",
    "        'C': 1,\n",
    "        'CC': 2,\n",
    "        'CCC': 3,\n",
    "        'B-': 4,\n",
    "        'B': 5,\n",
    "        'B+': 6,\n",
    "        'BB-': 7,\n",
    "        'BB': 8,\n",
    "        'BB+': 9,\n",
    "        'BBB-': 10,\n",
    "        'BBB': 11,\n",
    "        'BBB+': 12,\n",
    "        'A-': 13,\n",
    "        'A': 14,\n",
    "        'A+': 15,\n",
    "        'AA-': 16,\n",
    "        'AA': 17,\n",
    "        'AA+': 18,\n",
    "        'AAA': 19\n",
    "    }\n",
    "\n",
    "    # Check if the rating is a junk bond\n",
    "    if rating_values.get(rating, -1) >= 9:\n",
    "        return False  # Not a junk bond\n",
    "    else:\n",
    "        return True  # Junk bond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit['splticrm']=credit['splticrm'].apply(is_junk_bond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.002115509037143856\n",
      "accuracy Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit[ratio_name], credit[\"splticrm\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a LassoCV object and fit the model\n",
    "lasso_cv = LassoCV(cv=5)  # we can adjust the number of cross-validation folds with the cv parameter\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha value\n",
    "best_alpha = lasso_cv.alpha_\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lasso_cv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "score = accuracy_score(np.array(y_test).astype(int),np.array(y_pred).astype(int))\n",
    "print(\"accuracy Score:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 288, 377, 466, 555, 644, 733, 822, 911, 1000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'min_samples_split': [2, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter range \n",
    "\n",
    "# number of trees \n",
    "n_estimator = [int(x) for x in np.linspace(start =200, stop=1000,num=10)]\n",
    "# number of feature at each split\n",
    "max_features = ['auto','sqrt']\n",
    "# max depth \n",
    "max_depth = [int(x) for x in np.linspace(start =10, stop=100,num=10)]\n",
    "# min number of sample at each split \n",
    "min_sam_split = [2,5,10]\n",
    "\n",
    "\n",
    "# Create a random grid \n",
    "rnd_grid= {'n_estimators':n_estimator,\n",
    "          'max_features':max_features,\n",
    "          'max_depth' :max_depth,\n",
    "          'min_samples_split' :min_sam_split}\n",
    "\n",
    "print(rnd_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   43.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 288, 377, 466,\n",
       "                                                         555, 644, 733, 822,\n",
       "                                                         911, 1000]},\n",
       "                   random_state=33, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use random search to select best hyperparameters \n",
    "# cv (Cross Validation) specifies number of times (3 fold in this case) that\n",
    "# each hyper parameter combination will be evaluated)\n",
    "\n",
    "rfn=RandomForestClassifier()\n",
    "\n",
    "rfn_random = RandomizedSearchCV(estimator=rfn,param_distributions =rnd_grid,\n",
    "                               n_iter = 10,cv=3,verbose=2,random_state=33,n_jobs=-1,return_train_score=True)\n",
    "\n",
    "rfn_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random best hyperparameter accuracy:  0.7705882352941177\n"
     ]
    }
   ],
   "source": [
    "best_random = rfn_random.best_estimator_\n",
    "best_random.fit(X_train,y_train)\n",
    "y_pred_rnd = best_random.predict(X_test)\n",
    "rnd_accuracy = accuracy_score(np.array(y_test), y_pred_rnd)\n",
    "\n",
    "print('Random best hyperparameter accuracy: ',rnd_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-97ad0a14ffee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-b6aebd0c8668>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-b6aebd0c8668>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install tensorflow\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
